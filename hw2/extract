#!/usr/bin/env python

import argparse
import json
import os, sys, math, string
import morfessor
import codecs

def extract_features(hyp, ref,args):
  recall = compute_recall(hyp, ref, args)
  exact = 1 if hyp == ref else 0
  return {'recall':recall, 'exact':exact}

def get_chunks(hwords, rwords):
	hset = set(hwords)
	rset = set(rwords)



	hword_reduced = [word for word in hwords if word in rset]
	rword_reduced = [word for word in rwords if word in hset]


	chunks = 0
	i = 0
	while i < len(hword_reduced):
		index = rword_reduced.index(hword_reduced[i])

		start = i
		index = index + 1

		for j in xrange(start+1,len(hword_reduced)):
			if index == len(rword_reduced):
				break
			if(rword_reduced[index] != hword_reduced[j]):
				break
			i = i+1
			index = index+1
		chunks = chunks + 1
		i = i+1

	return (chunks, len(hword_reduced))


def compute_recall(hyp, ref,args):
  full_weight = float(args.weight)
  trunc_weight = 1- full_weight



  hwords = hyp.lower().split()
  rwords = ref.lower().split()
  hypset = set(hwords)
  refset = set(rwords)

  hwords_trunc = [word[:3] for word in hwords]
  rwords_trunc = [word[:3] for word in rwords]
  hypset_trunc = set(hwords_trunc)
  refset_trunc = set(rwords_trunc)



  recall = (sum(full_weight for word in refset if word in hypset) + \
              sum(trunc_weight for word in refset_trunc if word in hypset_trunc)) / \
  		      len(refset)*(full_weight + trunc_weight)

  return recall

def get_data(args):
	train = set()
	input_file = codecs.open(args.pairs,'r', 'utf-8')

	for ref_hyp in input_file:
		ref,hyp = ref_hyp.rstrip().split(' ||| ')
		train.add(ref)
	return train

def train_model(args):
	train_data = list(get_data(args))
	print train_data
	model = morfessor.BaselineModel()
	model.load_data(train_data)
	model.train_batch()
	return model

argparser = argparse.ArgumentParser(prog='extract')
argparser.add_argument('-x', '--pairs', dest='pairs', default='data/en-cs.pairs', help='Reference-Hypothesis pairs')
argparser.add_argument('-f', dest='full')
argparser.add_argument('-t', dest='trunc')
argparser.add_argument('-w', dest='weight')
argparser.add_argument('-g', dest='gamma')
argparser.add_argument('-b', dest='beta')

args = argparser.parse_args()

model = train_model(args)

lc = 0
sys.stderr.write('Extracting features for (ref,hyp) pairs from %s.\n' % args.pairs)
# loop over all (ref,hyp) pairs in the input file and extract evaluation features

input_file = codecs.open(args.pairs, 'r' , 'utf-8')

for ref_hyp in input_file:
  lc += 1
  ref, hyp = ref_hyp.rstrip().split(' ||| ')
  fmap = extract_features(hyp, ref,args)
  print json.dumps(fmap)   # print evaluation feature map

